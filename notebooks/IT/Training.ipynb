{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training attention based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train_model import train\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8, 4)\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['axes.facecolor'] = '#ffffff'\n",
    "rcParams['lines.linewidth'] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file D:\\Final_file\\ASI-main\\output\\models\\IT\\asi_IT_weights.hdf5 does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = r\"D:\\Final_file\\ASI-main\\output\\models\\IT\\asi_IT_weights.hdf5\"\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed the file: {file_path}\")\n",
    "else:\n",
    "    print(f\"The file {file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BEST IT\n",
    "\n",
    "hyperparameter={\n",
    "\"num_nearest\":40,\n",
    "\"sigma\":2,\n",
    "\"geointerpolation\": 'asi_multi',\n",
    "'type_compat_funct_eucli':'identity',\n",
    "'Num_heads':8,\n",
    "\"learning_rate\":0.001,\n",
    "\"batch_size\":32,\n",
    "\"num_neuron\":60,\n",
    "\"num_layers\":5,\n",
    "\"size_embedded\":50,\n",
    "\"num_nearest_geo\":30,\n",
    "\"num_nearest_eucli\":25,\n",
    "\"id_dataset\":'IT',\n",
    "\"epochs\":300,\n",
    "\"optimier\":'adam',\n",
    "\"validation_split\":0.1,\n",
    "\"label\":'asi_IT',\n",
    "\"early_stopping\": False,\n",
    "'scale_log':False,\n",
    "\"graph_label\":'matrix',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = train(**hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/300\n",
      "696/696 [==============================] - 4s 3ms/step - loss: 78683.2734 - root_mean_squared_error: 128274.8438 - val_loss: 41367.1406 - val_root_mean_squared_error: 58249.8008\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 41367.14062, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 2/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 38067.1211 - root_mean_squared_error: 53611.0938 - val_loss: 39765.5352 - val_root_mean_squared_error: 55660.0898\n",
      "\n",
      "Epoch 00002: val_loss improved from 41367.14062 to 39765.53516, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 3/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 36290.2109 - root_mean_squared_error: 51551.6641 - val_loss: 35760.2266 - val_root_mean_squared_error: 51305.9922\n",
      "\n",
      "Epoch 00003: val_loss improved from 39765.53516 to 35760.22656, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 4/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 35217.7930 - root_mean_squared_error: 50305.8711 - val_loss: 35298.0547 - val_root_mean_squared_error: 50855.3789\n",
      "\n",
      "Epoch 00004: val_loss improved from 35760.22656 to 35298.05469, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 5/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 34560.2891 - root_mean_squared_error: 49609.2070 - val_loss: 35831.8516 - val_root_mean_squared_error: 51318.4648\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 35298.05469\n",
      "Epoch 6/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 34220.5898 - root_mean_squared_error: 49099.5859 - val_loss: 34630.2969 - val_root_mean_squared_error: 50264.5586\n",
      "\n",
      "Epoch 00006: val_loss improved from 35298.05469 to 34630.29688, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 7/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 33939.2617 - root_mean_squared_error: 48819.7578 - val_loss: 34284.9141 - val_root_mean_squared_error: 49673.3789\n",
      "\n",
      "Epoch 00007: val_loss improved from 34630.29688 to 34284.91406, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 8/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 33179.5430 - root_mean_squared_error: 47982.4258 - val_loss: 34107.4180 - val_root_mean_squared_error: 49267.6797\n",
      "\n",
      "Epoch 00008: val_loss improved from 34284.91406 to 34107.41797, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 9/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 32883.4531 - root_mean_squared_error: 47688.4609 - val_loss: 33866.2148 - val_root_mean_squared_error: 49415.1836\n",
      "\n",
      "Epoch 00009: val_loss improved from 34107.41797 to 33866.21484, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 10/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 32608.8301 - root_mean_squared_error: 47440.9844 - val_loss: 34219.8281 - val_root_mean_squared_error: 50138.9570\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 33866.21484\n",
      "Epoch 11/300\n",
      "696/696 [==============================] - 2s 3ms/step - loss: 32234.2305 - root_mean_squared_error: 47007.7695 - val_loss: 33803.8164 - val_root_mean_squared_error: 49294.3125\n",
      "\n",
      "Epoch 00011: val_loss improved from 33866.21484 to 33803.81641, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 12/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 32062.8809 - root_mean_squared_error: 46979.3320 - val_loss: 33972.8359 - val_root_mean_squared_error: 49882.2617\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 33803.81641\n",
      "Epoch 13/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 31906.9004 - root_mean_squared_error: 46781.8672 - val_loss: 33788.7305 - val_root_mean_squared_error: 49497.7148\n",
      "\n",
      "Epoch 00013: val_loss improved from 33803.81641 to 33788.73047, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 14/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 31574.9668 - root_mean_squared_error: 46405.2695 - val_loss: 32931.0664 - val_root_mean_squared_error: 48594.4570\n",
      "\n",
      "Epoch 00014: val_loss improved from 33788.73047 to 32931.06641, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 15/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 31620.6152 - root_mean_squared_error: 46381.0078 - val_loss: 32892.1406 - val_root_mean_squared_error: 48495.1953\n",
      "\n",
      "Epoch 00015: val_loss improved from 32931.06641 to 32892.14062, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 16/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 31387.0254 - root_mean_squared_error: 46243.6211 - val_loss: 32734.7227 - val_root_mean_squared_error: 48360.7227\n",
      "\n",
      "Epoch 00016: val_loss improved from 32892.14062 to 32734.72266, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 17/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 31218.8828 - root_mean_squared_error: 46191.8984 - val_loss: 33848.8750 - val_root_mean_squared_error: 49658.7773\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 32734.72266\n",
      "Epoch 18/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 31068.7070 - root_mean_squared_error: 45879.4180 - val_loss: 33628.2734 - val_root_mean_squared_error: 49411.1289\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 32734.72266\n",
      "Epoch 19/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30915.3145 - root_mean_squared_error: 45759.5820 - val_loss: 33145.4414 - val_root_mean_squared_error: 48797.1602\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 32734.72266\n",
      "Epoch 20/300\n",
      "696/696 [==============================] - 2s 3ms/step - loss: 30847.8398 - root_mean_squared_error: 45550.7305 - val_loss: 32376.8633 - val_root_mean_squared_error: 47847.6758\n",
      "\n",
      "Epoch 00020: val_loss improved from 32734.72266 to 32376.86328, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 21/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30676.5488 - root_mean_squared_error: 45479.7305 - val_loss: 32334.6777 - val_root_mean_squared_error: 47988.5000\n",
      "\n",
      "Epoch 00021: val_loss improved from 32376.86328 to 32334.67773, saving model to C:\\Users\\shubh\\Desktop\\House Price Prediction\\Boosting-House-Price-Estimations-with-Multi-Head-Gated-Attention\\ASI-main/output/models/IT\\asi_IT_weights.hdf5\n",
      "Epoch 22/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30452.0156 - root_mean_squared_error: 45256.3438 - val_loss: 33203.6914 - val_root_mean_squared_error: 49080.1484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: val_loss did not improve from 32334.67773\n",
      "Epoch 23/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30391.7656 - root_mean_squared_error: 45164.6719 - val_loss: 32582.5195 - val_root_mean_squared_error: 48006.0352\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 32334.67773\n",
      "Epoch 24/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30384.9863 - root_mean_squared_error: 45233.2305 - val_loss: 34109.3516 - val_root_mean_squared_error: 49890.1289\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 32334.67773\n",
      "Epoch 25/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30465.3516 - root_mean_squared_error: 45174.0781 - val_loss: 32632.2461 - val_root_mean_squared_error: 48442.8320\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 32334.67773\n",
      "Epoch 26/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30266.5684 - root_mean_squared_error: 45063.6641 - val_loss: 32611.9805 - val_root_mean_squared_error: 48323.9453\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 32334.67773\n",
      "Epoch 27/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30275.6680 - root_mean_squared_error: 45104.4219 - val_loss: 32650.4219 - val_root_mean_squared_error: 48205.0508\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 32334.67773\n",
      "Epoch 28/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 30067.9414 - root_mean_squared_error: 44813.9805 - val_loss: 32591.2012 - val_root_mean_squared_error: 48215.6016\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 32334.67773\n",
      "Epoch 29/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 29939.6953 - root_mean_squared_error: 44674.9531 - val_loss: 32671.2012 - val_root_mean_squared_error: 48567.0547\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 32334.67773\n",
      "Epoch 30/300\n",
      "696/696 [==============================] - 2s 2ms/step - loss: 29857.8633 - root_mean_squared_error: 44644.3555 - val_loss: 33687.4844 - val_root_mean_squared_error: 49438.3281\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 32334.67773\n",
      "Epoch 31/300\n",
      "696/696 [==============================] - 2s 3ms/step - loss: 29852.0820 - root_mean_squared_error: 44743.5859 - val_loss: 32576.4551 - val_root_mean_squared_error: 48435.6641\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 32334.67773\n",
      "Epoch 32/300\n",
      "696/696 [==============================] - 3s 5ms/step - loss: 29737.0195 - root_mean_squared_error: 44432.8984 - val_loss: 32397.7129 - val_root_mean_squared_error: 48324.2539\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 32334.67773\n",
      "Epoch 33/300\n",
      "474/696 [===================>..........] - ETA: 0s - loss: 29580.2168 - root_mean_squared_error: 44194.050"
     ]
    }
   ],
   "source": [
    "dataset,\\\n",
    "result,\\\n",
    "fit,\\\n",
    "embedded_train,\\\n",
    "embedded_test,\\\n",
    "predict_regression_train,\\\n",
    "predict_regression_test = spatial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asi\n",
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asi_multi\n",
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\Final_file\\ASI-main\\datasets\\IT\\data.npz'\n",
    "data = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the mean absolute percentage error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def mean_absolute_log_error(y_true, y_pred):\n",
    "    # Ensure all values are positive with a small constant (e.g., 1e-10)\n",
    "    y_true_pos = np.maximum(y_true, 1e-10) + 1\n",
    "    y_pred_pos = np.maximum(y_pred, 1e-10) + 1\n",
    "    y_true_log = np.log(y_true_pos)\n",
    "    y_pred_log = np.log(y_pred_pos)\n",
    "    return mean_absolute_error(y_true_log, y_pred_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models benchmarking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "test_male_list = {} \n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [200,400,1000], 'learning_rate': [0.05]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0),\n",
    "        'params': {'depth': [ 8, 10], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor( learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "    test_male_list[name] = [] \n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "        test_male = mean_absolute_log_error((y_test), (y_pred_test)) \n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "        test_male_list[name].append(test_male)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "    avg_test_male = np.mean(test_male_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "    best_test_male = np.min(test_male_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(f\"Average Test MALE: {avg_test_male}, Best Test MALE: {best_test_male}\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = embedded_train,embedded_test,dataset.y_train,dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "test_male_list = {} \n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [200,400,1000], 'learning_rate': [0.05]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0),\n",
    "        'params': {'depth': [ 8, 10], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor( learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "    test_male_list[name] = [] \n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "        test_male = mean_absolute_error(np.log1p(y_test), np.log1p(y_pred_test)) \n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "        test_male_list[name].append(test_male)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "    avg_test_male = np.mean(test_male_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "    best_test_male = np.min(test_male_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(f\"Average Test MALE: {avg_test_male}, Best Test MALE: {best_test_male}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
